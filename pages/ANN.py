import numpy as np
import pickle
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import pandas as pd
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import ConfusionMatrixDisplay
import streamlit as st

import pandas as pd
from sklearn.model_selection import train_test_split
import streamlit as st
from sklearn.neural_network import MLPClassifier
from joblib import dump, load

@st.cache # Add caching to the function
def load_data():
    # Load data from CSV
    df = pd.read_csv('C:\\Users\\Owner\\PycharmProjects\\pythonProject\\Malware_detection\\main code\\final_data.csv')

    # Preprocess data
    y = df['malware']
    X = df.drop(['malware'], axis=1)

    # Split data into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

    return X_train, X_test, y_train, y_test

st.set_page_config(page_title='ANN', layout='wide')

# Load data using the cached function
X_train, X_test, y_train, y_test = load_data()

st.subheader('1. Dataset')
st.markdown('**1.1. Glimpse of dataset**')
st.write(X_train.head())
st.markdown('**1.2. malware count**')
st.write(y_train.value_counts())

# Bar chart showing the distribution of malware vs non-malware samples in the training set
st.subheader('1.3. Distribution of malware vs non-malware samples')
fig, ax = plt.subplots(figsize=(6, 4))
sns.countplot(x=y_train, ax=ax)
ax.set_title('Distribution of malware vs non-malware samples')
st.pyplot(fig)

st.subheader('2. TRAIN TEST SPLIT')
st.write('Training set')
st.write(X_train.shape)
st.write('Testing set')
st.write(X_test.shape)

# Train the model
clf = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000).fit(X_train, y_train)

# Save the trained model to disk
dump(clf, 'model.joblib')

# Load the saved model from disk
clf = load('model.joblib')

# Use the loaded model to make predictions
predictions = clf.predict(X_test)

# Display the confusion matrix
@st.cache # Add caching to the function
def get_confusion_matrix(y_true, y_pred):
    return confusion_matrix(y_true, y_pred)


st.subheader('3. Confusion matrix')
lgmt = get_confusion_matrix(y_test, predictions)
fig, ax = plt.subplots(figsize=(4, 4))
disp = ConfusionMatrixDisplay(confusion_matrix=lgmt, display_labels=['0', '1'])
disp.plot(ax=ax)
ax.set_title("Confusion Matrix")
ax.set_xlabel("Predicted label")
ax.set_ylabel("True label")
st.pyplot(fig)

# Calculate performance metrics
tn_log, fp_log, fn_log, tp_log = confusion_matrix(y_test, predictions).ravel()

accuracy_log = (tp_log + tn_log) / (tp_log + tn_log + fp_log + fn_log)
precision_log = tp_log / (tp_log + fp_log)
recall_log = tp_log / (tp_log + fn_log)
f1_score_log = 2 * ((precision_log * recall_log) / (precision_log + recall_log))

# Display the performance metrics
st.subheader('4. ACCURACY')
st.write("The accuracy of logistic regression algorithm is :", accuracy_log)
st.write("The precision of logistic regression algorithm is :", precision_log)
st.write("F1 score of logistic regression algorithm is :", f1_score_log)




# Display ROC curve
st.subheader('6. ROC CURVE')
from sklearn.metrics import roc_auc_score, roc_curve

# Import plotly library
import plotly.graph_objects as go

# Use the loaded model to make predictions
y_pred_proba = clf.predict_proba(X_test)[:,1]

# Calculate false positive rate, true positive rate, and thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

# Calculate AUC score
roc_auc = roc_auc_score(y_test, y_pred_proba)

# Create an interactive ROC curve plot
fig = go.Figure()
fig.add_trace(go.Scatter(x=fpr, y=tpr,
                    mode='lines',
                    name='ROC Curve (AUC = %0.2f)' % roc_auc))
fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1],
                    mode='lines',
                    line=dict(dash='dash', color='gray'),
                    showlegend=False))
fig.update_layout(
    title='Receiver Operating Characteristic (ROC) Curve',
    xaxis_title='False Positive Rate',
    yaxis_title='True Positive Rate',
    xaxis=dict(range=[0,1]),
    yaxis=dict(range=[0,1])
)
st.plotly_chart(fig)


st.markdown(
"""
<style>
    [data-testid="stSidebarNav"] {
        background-image: url(https://kjsit.somaiya.edu.in/assets/kjsieit/images/Logo/kjsieit-logo.svg);
        background-repeat: no-repeat;
        padding-top: 120px;
        background-position: 20px 20px;
    }

</style>
"""
, unsafe_allow_html=True)
